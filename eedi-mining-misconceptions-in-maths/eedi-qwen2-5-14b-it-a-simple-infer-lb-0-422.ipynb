{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T14:32:17.632718Z","iopub.status.busy":"2024-12-06T14:32:17.632373Z","iopub.status.idle":"2024-12-06T14:32:28.882988Z","shell.execute_reply":"2024-12-06T14:32:28.881863Z","shell.execute_reply.started":"2024-12-06T14:32:17.632659Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: /kaggle/input/lmsys-wheel-files\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n","Processing /kaggle/input/lmsys-wheel-files/peft-0.11.1-py3-none-any.whl\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Installing collected packages: peft\n","Successfully installed peft-0.11.1\n"]}],"source":["!pip install transformers peft accelerate \\\n","    -U --no-index --find-links /kaggle/input/lmsys-wheel-files"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T14:32:50.203851Z","iopub.status.busy":"2024-12-06T14:32:50.203388Z","iopub.status.idle":"2024-12-06T14:33:01.722354Z","shell.execute_reply":"2024-12-06T14:33:01.721372Z","shell.execute_reply.started":"2024-12-06T14:32:50.203815Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!pip install --no-index /kaggle/input/bitsandbytes0-42-0/bitsandbytes-0.42.0-py3-none-any.whl --find-links=/kaggle/input/bitsandbytes0-42-0\n","# !pip install --no-index  /kaggle/input/bitsandbytes0-42-0/optimum-1.21.2-py3-none-any.whl --find-links=/kaggle/input/bitsandbytes0-42-0\n","# !pip install --no-index  /kaggle/input/bitsandbytes0-42-0/auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --find-links=/kaggle/input/bitsandbytes0-42-0"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# for explaining attention masks\n","# Original sentences\n","sentences = [\n","    \"Hello world\",           # 2 tokens\n","    \"I love programming\"     # 3 tokens\n","]\n","\n","# After tokenization and padding to max_length=4\n","input_ids = [\n","    [101, 202, 303, 0],    # \"Hello world [PAD]\"\n","    [101, 202, 303, 404]   # \"I love programming\"\n","]\n","\n","# Corresponding attention mask\n","attention_mask = [\n","    [1, 1, 1, 0],    # Last token is padding (0)\n","    [1, 1, 1, 1]     # All tokens are real (1)\n","]"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T14:35:13.702936Z","iopub.status.busy":"2024-12-06T14:35:13.702418Z","iopub.status.idle":"2024-12-06T14:35:29.644331Z","shell.execute_reply":"2024-12-06T14:35:29.643404Z","shell.execute_reply.started":"2024-12-06T14:35:13.702901Z"},"trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm\n","from bs4 import BeautifulSoup\n","import gc\n","import pandas as pd\n","import pickle\n","import sys\n","import numpy as np\n","from tqdm.autonotebook import trange\n","from sklearn.model_selection import GroupKFold\n","import json\n","import torch\n","from numpy.linalg import norm\n","import torch.nn.functional as F\n","from torch import Tensor\n","from transformers import AutoTokenizer, AutoModel,BitsAndBytesConfig\n","from peft import (\n","    LoraConfig,\n","    get_peft_model,\n",")\n","import json\n","import copy\n","import warnings\n","import os\n","warnings.filterwarnings('ignore')\n","\n","def apk(actual, predicted, k=25):\n","    \"\"\"\n","    Computes the average precision at k.\n","    \n","    This function computes the average prescision at k between two lists of\n","    items.\n","    \n","    Parameters\n","    ----------\n","    actual : list\n","             A list of elements that are to be predicted (order doesn't matter)\n","    predicted : list\n","                A list of predicted elements (order does matter)\n","    k : int, optional\n","        The maximum number of predicted elements\n","        \n","    Returns\n","    -------\n","    score : double\n","            The average precision at k over the input lists\n","    \"\"\"\n","    \n","    if not actual:\n","        return 0.0\n","\n","    if len(predicted)>k:\n","        predicted = predicted[:k]\n","\n","    score = 0.0\n","    num_hits = 0.0\n","\n","    for i,p in enumerate(predicted):\n","        # first condition checks whether it is valid prediction\n","        # second condition checks if prediction is not repeated\n","        if p in actual and p not in predicted[:i]:\n","            num_hits += 1.0\n","            score += num_hits / (i+1.0)\n","\n","    return score / min(len(actual), k)\n","\n","def mapk(actual, predicted, k=25):\n","    \"\"\"\n","    Computes the mean average precision at k.\n","    \n","    This function computes the mean average prescision at k between two lists\n","    of lists of items.\n","    \n","    Parameters\n","    ----------\n","    actual : list\n","             A list of lists of elements that are to be predicted \n","             (order doesn't matter in the lists)\n","    predicted : list\n","                A list of lists of predicted elements\n","                (order matters in the lists)\n","    k : int, optional\n","        The maximum number of predicted elements\n","        \n","    Returns\n","    -------\n","    score : double\n","            The mean average precision at k over the input lists\n","    \"\"\"\n","    \n","    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n","\n","def batch_to_device(batch, target_device):\n","    \"\"\"\n","    send a pytorch batch to a device (CPU/GPU)\n","    \"\"\"\n","    for key in batch:\n","        if isinstance(batch[key], Tensor):\n","            batch[key] = batch[key].to(target_device)\n","    return batch\n","\n","def last_token_pool(last_hidden_states: Tensor,\n","                    attention_mask: Tensor) -> Tensor:\n","    \"\"\"\n","    Extracts the last meaningful token from a sequence, handling both left and right padding\n","    \"\"\"\n","    # Check if padding is on the left side\n","    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n","    if left_padding:\n","        # If left-padded, last token is always at the end\n","        return last_hidden_states[:, -1]\n","    else:\n","        # For right-padded sequences, find the last actual token position\n","        sequence_lengths = attention_mask.sum(dim=1) - 1\n","        batch_size = last_hidden_states.shape[0]\n","        # Get the last actual token for each sequence in the batch\n","        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n","\n","def get_detailed_instruct(task_description: str, query: str) -> str:\n","    return f'Instruct: {task_description}\\nQuery: {query}'\n","\n","def inference(df, model, tokenizer, device):\n","    # Initialize batch parameters\n","    batch_size = 16\n","    max_length = 512\n","    \n","    # Extract sentences and their IDs from dataframe\n","    sentences = list(df['query_text'].values)\n","    pids = list(df['order_index'].values)\n","    all_embeddings = []\n","\n","    # Sort sentences by length (longest first) for efficient batching\n","    length_sorted_idx = np.argsort([-len(sen) for sen in sentences])\n","    sentences_sorted = [sentences[idx] for idx in length_sorted_idx]\n","\n","    # Process sentences in batches\n","    for start_index in trange(0, len(sentences), batch_size, desc=\"Batches\", disable=False):\n","        # Get current batch of sentences\n","        sentences_batch = sentences_sorted[start_index: start_index + batch_size]\n","        \n","        # Tokenize the batch\n","        features = tokenizer(\n","            sentences_batch, \n","            max_length=max_length, \n","            padding=True, \n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","        \n","        # Move batch to specified device (CPU/GPU)\n","        features = batch_to_device(features, device)\n","        \n","        # Generate embeddings\n","        with torch.no_grad():  # Disable gradient calculation for inference\n","            outputs = model(**features)\n","            # Get the last token embeddings\n","            embeddings = last_token_pool(outputs.last_hidden_state, features['attention_mask'])\n","            # Normalize the embeddings\n","            embeddings = torch.nn.functional.normalize(embeddings, dim=-1)\n","            # Convert to numpy and store\n","            embeddings = embeddings.detach().cpu().numpy().tolist()\n","        all_embeddings.extend(embeddings)\n","\n","    # Restore original order of embeddings\n","    all_embeddings = [np.array(all_embeddings[idx]).reshape(1, -1) \n","                     for idx in np.argsort(length_sorted_idx)]\n","\n","    # Combine all embeddings into a single array\n","    sentence_embeddings = np.concatenate(all_embeddings, axis=0)\n","    \n","    # Create dictionary mapping IDs to embeddings\n","    result = {pids[i]: em for i, em in enumerate(sentence_embeddings)}\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # example usage\n","# # Moving batch to GPU\n","# batch = {\n","#     'input_ids': torch.tensor([[1, 2, 3]]),\n","#     'attention_mask': torch.tensor([[1, 1, 1]]),\n","#     'labels': torch.tensor([1])\n","# }\n","# batch = batch_to_device(batch, 'cuda')\n","\n","# # Getting last tokens from sequences\n","# hidden_states = torch.randn(32, 128, 768)  # batch_size=32, seq_len=128, hidden_dim=768\n","# attention_mask = torch.ones(32, 128)  # batch_size=32, seq_len=128\n","# last_tokens = last_token_pool(hidden_states, attention_mask)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T14:35:52.637648Z","iopub.status.busy":"2024-12-06T14:35:52.637113Z","iopub.status.idle":"2024-12-06T14:35:52.642126Z","shell.execute_reply":"2024-12-06T14:35:52.641217Z","shell.execute_reply.started":"2024-12-06T14:35:52.637616Z"},"trusted":true},"outputs":[],"source":["path_prefix = \"/kaggle/input/eedi-mining-misconceptions-in-mathematics\"\n","# model_path = \"/kaggle/input/sfr-embedding-mistral/SFR-Embedding-2_R\"\n","model_path = \"/kaggle/input/qwen2.5-14/pytorch/default/1\"\n","\n","lora_path='/kaggle/input/qwen14b-it-lora/lora_weights/adapter.bin'\n","device='cuda:0'\n","VALID = False"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T14:39:53.896906Z","iopub.status.busy":"2024-12-06T14:39:53.896489Z","iopub.status.idle":"2024-12-06T14:43:51.793320Z","shell.execute_reply":"2024-12-06T14:43:51.792274Z","shell.execute_reply.started":"2024-12-06T14:39:53.896875Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98459f47206e425880a4a1b6ca17eada","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["loading lora\n"]}],"source":["# Load the tokenizer from the base model directory\n","# Removing 'lora_weights/adapter.bin' from the path to get to the base directory\n","# which contains the original model's tokenizer files\n","tokenizer = AutoTokenizer.from_pretrained(lora_path.replace(\"/adapter.bin\",\"\"))\n","\n","# Configure 4-bit quantization settings using bitsandbytes\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,                         # Enable 4-bit quantization\n","    bnb_4bit_use_double_quant=True,           # Enable double quantization for additional memory savings\n","    bnb_4bit_quant_type=\"nf4\",                # Use 4-bit NormalFloat (NF4) data type\n","    bnb_4bit_compute_dtype=torch.bfloat16     # Use bfloat16 for intermediate computations\n",")\n","\n","# Load the base model with quantization settings\n","model = AutoModel.from_pretrained(\n","    model_path,                               # Path to the base model\n","    quantization_config=bnb_config,           # Apply the quantization settings\n","    device_map=device,                        # Automatically map model across available devices\n","    trust_remote_code=True                    # Allow loading of remote code (needed for some models)\n",")\n","\n","# If LoRA weights are provided, load and apply them\n","if lora_path:\n","    print(\"loading lora\")\n","    \n","    # Configure LoRA architecture - must match the configuration used during original fine-tuning\n","    config = LoraConfig(\n","        r=64,                    # Rank of the LoRA update matrices\n","        lora_alpha=128,          # LoRA scaling factor\n","        target_modules=[         # List of model modules to apply LoRA to\n","            \"q_proj\",            # Query projection\n","            \"k_proj\",            # Key projection\n","            \"v_proj\",            # Value projection\n","            \"o_proj\",            # Output projection\n","            \"gate_proj\",         # Gate projection\n","            \"up_proj\",           # Upward projection\n","            \"down_proj\",         # Downward projection\n","        ],\n","        bias=\"none\",            # Don't train bias parameters\n","        lora_dropout=0.05,      \n","        task_type=\"FEATURE_EXTRACTION\",  \n","    )\n","    \n","    # Wrap the base model with LoRA architecture\n","    model = get_peft_model(model, config)\n","    \n","    # Load the pre-trained LoRA weights\n","    d = torch.load(lora_path, map_location=model.device)\n","    \n","    # Apply the LoRA weights to the model\n","    # strict=False allows loading partial state dictionaries\n","    model.load_state_dict(d, strict=False)\n","    \n","    # Merge LoRA weights with base model weights and cleanup\n","    # This combines the LoRA adaptations with the original weights\n","    model = model.merge_and_unload()\n","\n","# Set model to evaluation mode\n","# This disables dropout and other training-specific behaviors\n","model = model.eval()\n","# model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-21T12:52:52.321443Z","iopub.status.busy":"2024-11-21T12:52:52.321068Z","iopub.status.idle":"2024-11-21T12:52:52.325092Z","shell.execute_reply":"2024-11-21T12:52:52.324425Z","shell.execute_reply.started":"2024-11-21T12:52:52.321397Z"},"trusted":true},"outputs":[],"source":["# # 输出模型的参数名和参数值\n","# for name, param in model.named_parameters():\n","#     if \"base_model.model.layers.12.input_layernorm.weight\"  in name:\n","#         print(f\"参数名: {name}\")\n","#         print(f\"参数值: {param}\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T15:10:14.602964Z","iopub.status.busy":"2024-12-06T15:10:14.602212Z","iopub.status.idle":"2024-12-06T15:10:14.607332Z","shell.execute_reply":"2024-12-06T15:10:14.606371Z","shell.execute_reply.started":"2024-12-06T15:10:14.602929Z"},"trusted":true},"outputs":[],"source":["task_description = 'Given a math question with correct answer and a misconcepted incorrect answer, retrieve the most accurate misconception for the incorrect answer.'"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T15:10:39.885106Z","iopub.status.busy":"2024-12-06T15:10:39.884354Z","iopub.status.idle":"2024-12-06T15:10:40.002422Z","shell.execute_reply":"2024-12-06T15:10:40.001553Z","shell.execute_reply.started":"2024-12-06T15:10:39.885074Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(3, 11)\n"]}],"source":["if VALID:\n","    tra = pd.read_parquet(\"/kaggle/input/val-parquet/v1_val.parquet\")\n","    print(tra.shape)\n","else:\n","    tra = pd.read_csv(f\"{path_prefix}/test.csv\")\n","    print(tra.shape)\n","misconception_mapping = pd.read_csv(f\"{path_prefix}/misconception_mapping.csv\")\n","if tra.shape[0]<10:\n","    misconception_mapping = misconception_mapping.sample(n=5,random_state=2023)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T15:10:44.212953Z","iopub.status.busy":"2024-12-06T15:10:44.212578Z","iopub.status.idle":"2024-12-06T15:10:44.249324Z","shell.execute_reply":"2024-12-06T15:10:44.248317Z","shell.execute_reply.started":"2024-12-06T15:10:44.212922Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(9, 14)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["if VALID:\n","    train_data = []\n","    for _,row in tra.iterrows():\n","        for c in ['A','B','C','D']:\n","            if str(row[f\"Misconception{c}Id\"])!=\"nan\":\n","                # print(row[f\"Misconception{c}Id\"])\n","                real_answer_id = row['CorrectAnswer']\n","                real_text = row[f'Answer{real_answer_id}Text']\n","                query_text = f\"### SubjectName: {row['SubjectName']}\\n### ConstructName: {row['ConstructName']}\\n### Question: {row['QuestionText']}\\n### Correct Answer: {real_text}\\n### Misconcepte Incorrect answer: {row[f'Answer{c}Text']}\"\n","                row['query_text'] = get_detailed_instruct(task_description,query_text)\n","                row['answer_id'] = int(row[f\"Misconception{c}Id\"])\n","                train_data.append(copy.deepcopy(row))\n","    train_df = pd.DataFrame(train_data)\n","    train_df['order_index'] = list(range(len(train_df)))\n","else:\n","    train_data = []\n","    for _,row in tra.iterrows():\n","        for c in ['A','B','C','D']:\n","            if c ==row['CorrectAnswer']:\n","                continue\n","            if f'Answer{c}Text' not in row:\n","                continue\n","            real_answer_id = row['CorrectAnswer']\n","            real_text = row[f'Answer{real_answer_id}Text']\n","            query_text = f\"### SubjectName: {row['SubjectName']}\\n### ConstructName: {row['ConstructName']}\\n### Question: {row['QuestionText']}\\n### Correct Answer: {real_text}\\n### Misconcepte Incorrect answer: {row[f'Answer{c}Text']}\"\n","            row['query_text'] = get_detailed_instruct(task_description,query_text)\n","            row['answer_name'] = c\n","            train_data.append(copy.deepcopy(row))\n","    train_df = pd.DataFrame(train_data)\n","    train_df['order_index'] = list(range(len(train_df)))\n","train_df.shape"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T15:10:53.436312Z","iopub.status.busy":"2024-12-06T15:10:53.435967Z","iopub.status.idle":"2024-12-06T15:10:53.459616Z","shell.execute_reply":"2024-12-06T15:10:53.458507Z","shell.execute_reply.started":"2024-12-06T15:10:53.436284Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>QuestionId</th>\n","      <th>ConstructId</th>\n","      <th>ConstructName</th>\n","      <th>SubjectId</th>\n","      <th>SubjectName</th>\n","      <th>CorrectAnswer</th>\n","      <th>QuestionText</th>\n","      <th>AnswerAText</th>\n","      <th>AnswerBText</th>\n","      <th>AnswerCText</th>\n","      <th>AnswerDText</th>\n","      <th>query_text</th>\n","      <th>answer_name</th>\n","      <th>order_index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1869</td>\n","      <td>856</td>\n","      <td>Use the order of operations to carry out calcu...</td>\n","      <td>33</td>\n","      <td>BIDMAS</td>\n","      <td>A</td>\n","      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n","      <td>\\( 3 \\times(2+4)-5 \\)</td>\n","      <td>\\( 3 \\times 2+(4-5) \\)</td>\n","      <td>\\( 3 \\times(2+4-5) \\)</td>\n","      <td>Does not need brackets</td>\n","      <td>Instruct: Given a math question with correct a...</td>\n","      <td>B</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>1869</td>\n","      <td>856</td>\n","      <td>Use the order of operations to carry out calcu...</td>\n","      <td>33</td>\n","      <td>BIDMAS</td>\n","      <td>A</td>\n","      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n","      <td>\\( 3 \\times(2+4)-5 \\)</td>\n","      <td>\\( 3 \\times 2+(4-5) \\)</td>\n","      <td>\\( 3 \\times(2+4-5) \\)</td>\n","      <td>Does not need brackets</td>\n","      <td>Instruct: Given a math question with correct a...</td>\n","      <td>C</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>1869</td>\n","      <td>856</td>\n","      <td>Use the order of operations to carry out calcu...</td>\n","      <td>33</td>\n","      <td>BIDMAS</td>\n","      <td>A</td>\n","      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n","      <td>\\( 3 \\times(2+4)-5 \\)</td>\n","      <td>\\( 3 \\times 2+(4-5) \\)</td>\n","      <td>\\( 3 \\times(2+4-5) \\)</td>\n","      <td>Does not need brackets</td>\n","      <td>Instruct: Given a math question with correct a...</td>\n","      <td>D</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1870</td>\n","      <td>1612</td>\n","      <td>Simplify an algebraic fraction by factorising ...</td>\n","      <td>1077</td>\n","      <td>Simplifying Algebraic Fractions</td>\n","      <td>D</td>\n","      <td>Simplify the following, if possible: \\( \\frac{...</td>\n","      <td>\\( m+1 \\)</td>\n","      <td>\\( m+2 \\)</td>\n","      <td>\\( m-1 \\)</td>\n","      <td>Does not simplify</td>\n","      <td>Instruct: Given a math question with correct a...</td>\n","      <td>A</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1870</td>\n","      <td>1612</td>\n","      <td>Simplify an algebraic fraction by factorising ...</td>\n","      <td>1077</td>\n","      <td>Simplifying Algebraic Fractions</td>\n","      <td>D</td>\n","      <td>Simplify the following, if possible: \\( \\frac{...</td>\n","      <td>\\( m+1 \\)</td>\n","      <td>\\( m+2 \\)</td>\n","      <td>\\( m-1 \\)</td>\n","      <td>Does not simplify</td>\n","      <td>Instruct: Given a math question with correct a...</td>\n","      <td>B</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1870</td>\n","      <td>1612</td>\n","      <td>Simplify an algebraic fraction by factorising ...</td>\n","      <td>1077</td>\n","      <td>Simplifying Algebraic Fractions</td>\n","      <td>D</td>\n","      <td>Simplify the following, if possible: \\( \\frac{...</td>\n","      <td>\\( m+1 \\)</td>\n","      <td>\\( m+2 \\)</td>\n","      <td>\\( m-1 \\)</td>\n","      <td>Does not simplify</td>\n","      <td>Instruct: Given a math question with correct a...</td>\n","      <td>C</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1871</td>\n","      <td>2774</td>\n","      <td>Calculate the range from a list of data</td>\n","      <td>339</td>\n","      <td>Range and Interquartile Range from a List of Data</td>\n","      <td>B</td>\n","      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n","      <td>Only\\nTom</td>\n","      <td>Only\\nKatie</td>\n","      <td>Both Tom and Katie</td>\n","      <td>Neither is correct</td>\n","      <td>Instruct: Given a math question with correct a...</td>\n","      <td>A</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1871</td>\n","      <td>2774</td>\n","      <td>Calculate the range from a list of data</td>\n","      <td>339</td>\n","      <td>Range and Interquartile Range from a List of Data</td>\n","      <td>B</td>\n","      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n","      <td>Only\\nTom</td>\n","      <td>Only\\nKatie</td>\n","      <td>Both Tom and Katie</td>\n","      <td>Neither is correct</td>\n","      <td>Instruct: Given a math question with correct a...</td>\n","      <td>C</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1871</td>\n","      <td>2774</td>\n","      <td>Calculate the range from a list of data</td>\n","      <td>339</td>\n","      <td>Range and Interquartile Range from a List of Data</td>\n","      <td>B</td>\n","      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n","      <td>Only\\nTom</td>\n","      <td>Only\\nKatie</td>\n","      <td>Both Tom and Katie</td>\n","      <td>Neither is correct</td>\n","      <td>Instruct: Given a math question with correct a...</td>\n","      <td>D</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   QuestionId  ConstructId                                      ConstructName  \\\n","0        1869          856  Use the order of operations to carry out calcu...   \n","0        1869          856  Use the order of operations to carry out calcu...   \n","0        1869          856  Use the order of operations to carry out calcu...   \n","1        1870         1612  Simplify an algebraic fraction by factorising ...   \n","1        1870         1612  Simplify an algebraic fraction by factorising ...   \n","1        1870         1612  Simplify an algebraic fraction by factorising ...   \n","2        1871         2774            Calculate the range from a list of data   \n","2        1871         2774            Calculate the range from a list of data   \n","2        1871         2774            Calculate the range from a list of data   \n","\n","   SubjectId                                        SubjectName CorrectAnswer  \\\n","0         33                                             BIDMAS             A   \n","0         33                                             BIDMAS             A   \n","0         33                                             BIDMAS             A   \n","1       1077                    Simplifying Algebraic Fractions             D   \n","1       1077                    Simplifying Algebraic Fractions             D   \n","1       1077                    Simplifying Algebraic Fractions             D   \n","2        339  Range and Interquartile Range from a List of Data             B   \n","2        339  Range and Interquartile Range from a List of Data             B   \n","2        339  Range and Interquartile Range from a List of Data             B   \n","\n","                                        QuestionText            AnswerAText  \\\n","0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n","0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n","0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n","1  Simplify the following, if possible: \\( \\frac{...              \\( m+1 \\)   \n","1  Simplify the following, if possible: \\( \\frac{...              \\( m+1 \\)   \n","1  Simplify the following, if possible: \\( \\frac{...              \\( m+1 \\)   \n","2  Tom and Katie are discussing the \\( 5 \\) plant...              Only\\nTom   \n","2  Tom and Katie are discussing the \\( 5 \\) plant...              Only\\nTom   \n","2  Tom and Katie are discussing the \\( 5 \\) plant...              Only\\nTom   \n","\n","              AnswerBText            AnswerCText             AnswerDText  \\\n","0  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)  Does not need brackets   \n","0  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)  Does not need brackets   \n","0  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)  Does not need brackets   \n","1               \\( m+2 \\)              \\( m-1 \\)       Does not simplify   \n","1               \\( m+2 \\)              \\( m-1 \\)       Does not simplify   \n","1               \\( m+2 \\)              \\( m-1 \\)       Does not simplify   \n","2             Only\\nKatie     Both Tom and Katie      Neither is correct   \n","2             Only\\nKatie     Both Tom and Katie      Neither is correct   \n","2             Only\\nKatie     Both Tom and Katie      Neither is correct   \n","\n","                                          query_text answer_name  order_index  \n","0  Instruct: Given a math question with correct a...           B            0  \n","0  Instruct: Given a math question with correct a...           C            1  \n","0  Instruct: Given a math question with correct a...           D            2  \n","1  Instruct: Given a math question with correct a...           A            3  \n","1  Instruct: Given a math question with correct a...           B            4  \n","1  Instruct: Given a math question with correct a...           C            5  \n","2  Instruct: Given a math question with correct a...           A            6  \n","2  Instruct: Given a math question with correct a...           C            7  \n","2  Instruct: Given a math question with correct a...           D            8  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T15:11:17.471526Z","iopub.status.busy":"2024-12-06T15:11:17.470792Z","iopub.status.idle":"2024-12-06T15:11:52.597693Z","shell.execute_reply":"2024-12-06T15:11:52.596879Z","shell.execute_reply.started":"2024-12-06T15:11:17.471491Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b78d6835ff72423c989267e4dfa929ff","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_embeddings = inference(train_df, model, tokenizer, device)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T15:12:00.660198Z","iopub.status.busy":"2024-12-06T15:12:00.659090Z","iopub.status.idle":"2024-12-06T15:12:02.747650Z","shell.execute_reply":"2024-12-06T15:12:02.746739Z","shell.execute_reply.started":"2024-12-06T15:12:00.660162Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5154913a80884569ac37ac09fa95ce6d","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["misconception_mapping['query_text'] = misconception_mapping['MisconceptionName']\n","misconception_mapping['order_index'] = misconception_mapping['MisconceptionId']\n","doc_embeddings = inference(misconception_mapping, model, tokenizer, device)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T15:33:20.524783Z","iopub.status.busy":"2024-12-06T15:33:20.524387Z","iopub.status.idle":"2024-12-06T15:33:20.530243Z","shell.execute_reply":"2024-12-06T15:33:20.529434Z","shell.execute_reply.started":"2024-12-06T15:33:20.524748Z"},"trusted":true},"outputs":[],"source":["sentence_embeddings = np.concatenate([e.reshape(1, -1) for e in list(doc_embeddings.values())])\n","index_text_embeddings_index = {index: paper_id for index, paper_id in\n","                                         enumerate(list(doc_embeddings.keys()))}"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T15:33:22.586872Z","iopub.status.busy":"2024-12-06T15:33:22.586512Z","iopub.status.idle":"2024-12-06T15:33:22.629261Z","shell.execute_reply":"2024-12-06T15:33:22.627200Z","shell.execute_reply.started":"2024-12-06T15:33:22.586841Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8c46cf985b64c19b98a58b166813b0e","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["predicts_test = []\n","for _, row in tqdm(train_df.iterrows()):\n","    query_id = row['order_index']\n","    query_em = train_embeddings[query_id].reshape(1, -1)\n","    \n","    cosine_similarity = np.dot(query_em, sentence_embeddings.T).flatten()\n","    \n","    sort_index = np.argsort(-cosine_similarity)[:25]\n","    pids = [index_text_embeddings_index[index] for index in sort_index]\n","    predicts_test.append(pids)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-12-06T15:33:25.757448Z","iopub.status.busy":"2024-12-06T15:33:25.757056Z","iopub.status.idle":"2024-12-06T15:33:25.786880Z","shell.execute_reply":"2024-12-06T15:33:25.785979Z","shell.execute_reply.started":"2024-12-06T15:33:25.757415Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Submission file created successfully!\n"]}],"source":["if VALID:\n","    train_df['recall_ids'] = predicts_test\n","    print(mapk([[data] for data in train_df['answer_id'].values],train_df['recall_ids'].values))\n","else:\n","    train_df['MisconceptionId'] = [' '.join(map(str,c)) for c in predicts_test]\n","    sub = []\n","    for _,row in train_df.iterrows():\n","        sub.append(\n","            {\n","                \"QuestionId_Answer\":f\"{row['QuestionId']}_{row['answer_name']}\",\n","                \"MisconceptionId\":row['MisconceptionId']\n","            }\n","        )\n","    submission_df = pd.DataFrame(sub)\n","    submission_df.to_csv(\"submission.csv\", index=False)\n","    print(\"Submission file created successfully!\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":9738540,"sourceId":82695,"sourceType":"competition"},{"datasetId":5297895,"sourceId":8897601,"sourceType":"datasetVersion"},{"datasetId":5251603,"sourceId":9094368,"sourceType":"datasetVersion"},{"datasetId":5920031,"sourceId":9688062,"sourceType":"datasetVersion"},{"datasetId":5968152,"sourceId":9748502,"sourceType":"datasetVersion"},{"datasetId":5995078,"sourceId":9784958,"sourceType":"datasetVersion"},{"datasetId":6020151,"sourceId":9818805,"sourceType":"datasetVersion"},{"datasetId":6135443,"sourceId":9972502,"sourceType":"datasetVersion"},{"modelId":160606,"modelInstanceId":137919,"sourceId":162181,"sourceType":"modelInstanceVersion"},{"modelId":165390,"modelInstanceId":142811,"sourceId":167864,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
