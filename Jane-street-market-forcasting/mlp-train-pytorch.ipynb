{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Training Neural Networks (MLP) with PyTorch Lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T04:58:17.953615Z","iopub.status.busy":"2024-11-05T04:58:17.952915Z","iopub.status.idle":"2024-11-05T04:58:17.962711Z","shell.execute_reply":"2024-11-05T04:58:17.961348Z","shell.execute_reply.started":"2024-11-05T04:58:17.953574Z"},"trusted":true},"outputs":[],"source":["import os\n","import pickle\n","import polars as pl\n","import numpy as np\n","import pandas as pd\n","\n","import warnings\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pytorch_lightning as pl # pl改个名，还有感觉不一定用到\n","from pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\n","from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Timer\n","# from pytorch_lightning.loggers import WandbLogger\n","# import wandb\n","\n","from sklearn.metrics import r2_score\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_path = './input_df' if os.path.exists('./input_df') else '/kaggle/input/js24-preprocessing-create-lags/training.parquet'\n","TRAINING = True\n","train_name = os.path.join(\"./input_df/\", \"nn_input_df_with_lags.pickle\")\n","valid_name = os.path.join(\"./input_df/\", \"nn_valid_df_with_lags.pickle\")\n","\n","if TRAINING and not os.path.exists(train_name):\n","    df = pl.scan_parquet(f\"{input_path}/training.parquet\").collect().to_pandas()\n","    valid = pl.scan_parquet(f\"{input_path}/validation.parquet\").collect().to_pandas()\n","    df = pd.concat([df, valid]).reset_index(drop=True) # Author's method to boost LB, consider to change\n","    with open(train_name, \"wb\") as w:\n","        pickle.dump(df, w)\n","    with open(valid_name, \"wb\") as w:\n","        pickle.dump(valid, w)\n","elif TRAINING:\n","    with open(train_name, \"rb\") as r:\n","        df = pickle.load(r)\n","    with open(valid_name, \"rb\") as r:\n","        valid = pickle.load(r)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["feature_names = [f\"feature_{i:02d}\" for i in range(79)] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n","label_name = 'responder_6'\n","weight_name = 'weight'"]},{"cell_type":"markdown","metadata":{},"source":["# PyTorch Data Module Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T04:58:17.995267Z","iopub.status.busy":"2024-11-05T04:58:17.994912Z","iopub.status.idle":"2024-11-05T04:58:18.776454Z","shell.execute_reply":"2024-11-05T04:58:18.77564Z","shell.execute_reply.started":"2024-11-05T04:58:17.995223Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, df, accelerator):\n","        self.features = torch.FloatTensor(df[feature_names].values).to(accelerator)\n","        self.labels = torch.FloatTensor(df[label_name].values).to(accelerator)\n","        self.weights = torch.FloatTensor(df[weight_name].values).to(accelerator)\n","    \n","    def __len__(self):\n","        return len(self.labels)\n","    \n","    def __getitem__(self, idx):\n","        x = self.features[idx]\n","        y = self.labels[idx]\n","        w = self.weights[idx]\n","        return x, y, w\n","\n","\n","class DataModule(LightningDataModule):\n","    def __init__(self, train_df, batch_size, valid_df=None, accelerator='cpu'):\n","        super().__init__()\n","        self.df = train_df\n","        self.batch_size = batch_size\n","        self.dates = self.df['date_id'].unique()\n","        self.accelerator = accelerator\n","        self.train_dataset = None\n","        self.valid_df = None\n","        if valid_df is not None:\n","            self.valid_df = valid_df\n","        self.val_dataset = None\n","\n","    def setup(self, fold=0, N_fold=5, stage=None):\n","        # 为了做出5组不同的training set在后续实施环节，但没有将没选的数据加入validation set\n","        selected_dates = [date for ii, date in enumerate(self.dates) if ii % N_fold != fold]\n","        # separate some data from training set\n","        df_train = self.df.loc[self.df['date_id'].isin(selected_dates)]\n","        self.train_dataset = CustomDataset(df_train, self.accelerator)\n","        if self.valid_df is not None:\n","            df_valid = self.valid_df\n","            self.val_dataset = CustomDataset(df_valid, self.accelerator)\n","\n","    def train_dataloader(self, n_workers=0):\n","        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=n_workers)\n","\n","    def val_dataloader(self, n_workers=0):\n","        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=n_workers)"]},{"cell_type":"markdown","metadata":{},"source":["# NN Model Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T04:58:18.778953Z","iopub.status.busy":"2024-11-05T04:58:18.778669Z","iopub.status.idle":"2024-11-05T04:58:18.796672Z","shell.execute_reply":"2024-11-05T04:58:18.795818Z","shell.execute_reply.started":"2024-11-05T04:58:18.778923Z"},"trusted":true},"outputs":[],"source":["# Custom R2 metric for validation\n","def r2_val(y_true, y_pred, sample_weight):\n","    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n","    return r2\n","\n","\n","class NN(LightningModule):\n","    def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        layers = []\n","        in_dim = input_dim\n","        for i, hidden_dim in enumerate(hidden_dims):\n","            layers.append(nn.BatchNorm1d(in_dim))\n","            if i > 0:\n","                layers.append(nn.SiLU())\n","            if i < len(dropouts):\n","                layers.append(nn.Dropout(dropouts[i]))\n","            layers.append(nn.Linear(in_dim, hidden_dim))\n","            # layers.append(nn.ReLU())\n","            in_dim = hidden_dim\n","        layers.append(nn.Linear(in_dim, 1)) \n","        layers.append(nn.Tanh())\n","        self.model = nn.Sequential(*layers)\n","        self.lr = lr\n","        self.weight_decay = weight_decay\n","        self.validation_step_outputs = []\n","\n","    def forward(self, x):\n","        return 5 * self.model(x).squeeze(-1)  \n","\n","    def training_step(self, batch):\n","        x, y, w = batch\n","        y_hat = self(x)\n","        loss = F.mse_loss(y_hat, y, reduction='none') * w  #\n","        loss = loss.mean()\n","        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n","        return loss\n","\n","    def validation_step(self, batch):\n","        x, y, w = batch\n","        y_hat = self(x)\n","        loss = F.mse_loss(y_hat, y, reduction='none') * w\n","        loss = loss.mean()\n","        self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n","        self.validation_step_outputs.append((y_hat, y, w))\n","        return loss\n","\n","    def on_validation_epoch_end(self):\n","        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n","        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n","        if self.trainer.sanity_checking:\n","            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n","        else:\n","            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n","            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n","            # r2_val\n","            val_r_square = r2_val(y, prob, weights)\n","            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n","        self.validation_step_outputs.clear()\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n","                                                               verbose=True)\n","        return {\n","            'optimizer': optimizer,\n","            'lr_scheduler': {\n","                'scheduler': scheduler,\n","                'monitor': 'val_loss',\n","            }\n","        }\n","\n","    def on_train_epoch_end(self):\n","        if self.trainer.sanity_checking:\n","            return\n","        epoch = self.trainer.current_epoch\n","        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n","        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n","        print(f\"Epoch {epoch}: {formatted_metrics}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Training Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class custom_args():\n","    def __init__(self):\n","        self.usegpu = True\n","        self.gpuid = 0\n","        self.seed = 42\n","        self.model = 'nn'\n","        # self.use_wandb = False\n","        self.project = 'js-xs-nn-with-lags'\n","        self.dname = \"./input_df/\"\n","        self.loader_workers = 4\n","        self.bs = 8192\n","        self.lr = 1e-3\n","        self.weight_decay = 5e-4\n","        self.dropouts = [0.1, 0.1]\n","        self.n_hidden = [512, 512, 256]\n","        self.patience = 25\n","        self.max_epochs = 2000\n","        self.N_fold = 5\n","\n","\n","my_args = custom_args()"]},{"cell_type":"markdown","metadata":{},"source":["# Create PyTorch Data Module"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["args = my_args\n","\n","# checking device\n","device = torch.device(f'cuda:{args.gpuid}' if torch.cuda.is_available() and args.usegpu else 'cpu')\n","accelerator = 'gpu' if torch.cuda.is_available() and args.usegpu else 'cpu'\n","loader_device = 'cpu'\n","\n","\n","# Initialize Data Module\n","df[feature_names] = df[feature_names].fillna(method = 'ffill').fillna(0)  # 全的training set\n","valid[feature_names] = valid[feature_names].fillna(method = 'ffill').fillna(0) # 之前设好的validation set\n","data_module = DataModule(df, batch_size=args.bs, valid_df=valid, accelerator=loader_device)"]},{"cell_type":"markdown","metadata":{},"source":["# Create Model and Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T04:58:18.798262Z","iopub.status.busy":"2024-11-05T04:58:18.797992Z","iopub.status.idle":"2024-11-05T04:58:18.818565Z","shell.execute_reply":"2024-11-05T04:58:18.817654Z","shell.execute_reply.started":"2024-11-05T04:58:18.798232Z"},"trusted":true},"outputs":[],"source":["import gc\n","del df\n","gc.collect()\n","pl.seed_everything(args.seed)\n","\n","for fold in range(args.N_fold): # range(5)\n","    # 相当于用五组不同的training set 来分别训练\n","    data_module.setup(fold, args.N_fold)\n","    # Obtain input dimension\n","    input_dim = data_module.train_dataset.features.shape[1]\n","    # Initialize Model\n","    model = NN(\n","        input_dim=input_dim,\n","        hidden_dims=args.n_hidden,\n","        dropouts=args.dropouts,\n","        lr=args.lr,\n","        weight_decay=args.weight_decay\n","    )\n","    # Initialize Logger\n","    # if args.use_wandb:\n","    #    wandb_run = wandb.init(project=args.project, config=vars(args), reinit=True)\n","    #    logger = WandbLogger(experiment=wandb_run)\n","    # else:\n","    #    logger = None\n","    # Initialize Callbacks\n","    early_stopping = EarlyStopping('val_loss', patience=args.patience, mode='min', verbose=False)\n","    checkpoint_callback = ModelCheckpoint(monitor='val_loss', mode='min', save_top_k=1, verbose=False, filename=f\"./models/nn_{fold}.model\") \n","    timer = Timer()\n","    # Initialize Trainer\n","    trainer = Trainer(\n","        max_epochs=args.max_epochs,\n","        accelerator=accelerator,\n","        devices=[args.gpuid] if args.usegpu else None,\n","        # logger=logger,\n","        callbacks=[early_stopping, checkpoint_callback, timer],\n","        enable_progress_bar=True\n","    )\n","    # Start Training\n","    trainer.fit(model, data_module.train_dataloader(args.loader_workers), data_module.val_dataloader(args.loader_workers))\n","    # You can find trained best model in your local path\n","    print(f'Fold-{fold} Training completed in {timer.time_elapsed(\"train\"):.2f}s')\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9871156,"sourceId":84493,"sourceType":"competition"},{"sourceId":203900450,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"papermill":{"default_parameters":{},"duration":7.594014,"end_time":"2024-10-10T11:58:36.355301","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-10T11:58:28.761287","version":"2.6.0"}},"nbformat":4,"nbformat_minor":4}
