{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    seed = 2025\n",
    "    target_col = \"responder_6\"\n",
    "    # data_id is not included as it's not relavant\n",
    "    feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)] \\\n",
    "        + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "    encoded_cols = [f'encoded_feature_{i}' for i in range(16)]\n",
    "    categorical_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pl.scan_parquet(\"/root/autodl-tmp/jane-street-2024/training.parquet\").collect().to_pandas()\n",
    "# valid = pl.scan_parquet(\"/root/autodl-tmp/jane-street-2024/validation.parquet\").collect().to_pandas()\n",
    "# train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33290488, 21), (1643664, 21))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pl.scan_parquet(\"/root/autodl-tmp/jane-street-2024/encoded_train.parquet\").collect().to_pandas()\n",
    "valid = pl.scan_parquet(\"/root/autodl-tmp/jane-street-2024/encoded_valid.parquet\").collect().to_pandas()\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_feature_0</th>\n",
       "      <th>encoded_feature_1</th>\n",
       "      <th>encoded_feature_2</th>\n",
       "      <th>encoded_feature_3</th>\n",
       "      <th>encoded_feature_4</th>\n",
       "      <th>encoded_feature_5</th>\n",
       "      <th>encoded_feature_6</th>\n",
       "      <th>encoded_feature_7</th>\n",
       "      <th>encoded_feature_8</th>\n",
       "      <th>encoded_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>encoded_feature_11</th>\n",
       "      <th>encoded_feature_12</th>\n",
       "      <th>encoded_feature_13</th>\n",
       "      <th>encoded_feature_14</th>\n",
       "      <th>encoded_feature_15</th>\n",
       "      <th>responder_6</th>\n",
       "      <th>weight</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>time_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.168524</td>\n",
       "      <td>-0.057372</td>\n",
       "      <td>0.102818</td>\n",
       "      <td>-0.243955</td>\n",
       "      <td>-0.202454</td>\n",
       "      <td>-0.104967</td>\n",
       "      <td>0.321823</td>\n",
       "      <td>-0.222371</td>\n",
       "      <td>-0.262240</td>\n",
       "      <td>-0.180430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258119</td>\n",
       "      <td>-0.242541</td>\n",
       "      <td>-0.157287</td>\n",
       "      <td>-0.145760</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.496563</td>\n",
       "      <td>3.324375</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.162565</td>\n",
       "      <td>-0.060451</td>\n",
       "      <td>0.094373</td>\n",
       "      <td>-0.243832</td>\n",
       "      <td>-0.207173</td>\n",
       "      <td>-0.107619</td>\n",
       "      <td>0.317791</td>\n",
       "      <td>-0.222770</td>\n",
       "      <td>-0.263774</td>\n",
       "      <td>-0.184074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257707</td>\n",
       "      <td>-0.245912</td>\n",
       "      <td>-0.156141</td>\n",
       "      <td>-0.148324</td>\n",
       "      <td>-0.013658</td>\n",
       "      <td>0.529877</td>\n",
       "      <td>4.711303</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.164049</td>\n",
       "      <td>-0.259337</td>\n",
       "      <td>-0.201851</td>\n",
       "      <td>-0.278407</td>\n",
       "      <td>-0.252687</td>\n",
       "      <td>-0.257245</td>\n",
       "      <td>0.225601</td>\n",
       "      <td>-0.249530</td>\n",
       "      <td>-0.273658</td>\n",
       "      <td>-0.244420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042617</td>\n",
       "      <td>-0.223356</td>\n",
       "      <td>-0.231683</td>\n",
       "      <td>-0.271294</td>\n",
       "      <td>0.407031</td>\n",
       "      <td>0.746983</td>\n",
       "      <td>3.028847</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.271798</td>\n",
       "      <td>-0.055786</td>\n",
       "      <td>-0.239978</td>\n",
       "      <td>-0.229345</td>\n",
       "      <td>-0.060237</td>\n",
       "      <td>-0.220229</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>-0.208833</td>\n",
       "      <td>-0.147414</td>\n",
       "      <td>-0.217443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012005</td>\n",
       "      <td>-0.107234</td>\n",
       "      <td>-0.278464</td>\n",
       "      <td>-0.162567</td>\n",
       "      <td>-0.258254</td>\n",
       "      <td>0.941218</td>\n",
       "      <td>2.099438</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.269069</td>\n",
       "      <td>-0.106385</td>\n",
       "      <td>-0.235731</td>\n",
       "      <td>-0.240414</td>\n",
       "      <td>-0.079836</td>\n",
       "      <td>-0.237433</td>\n",
       "      <td>0.665825</td>\n",
       "      <td>-0.209488</td>\n",
       "      <td>-0.180263</td>\n",
       "      <td>-0.203104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017777</td>\n",
       "      <td>-0.128438</td>\n",
       "      <td>-0.277465</td>\n",
       "      <td>-0.186881</td>\n",
       "      <td>-0.277370</td>\n",
       "      <td>0.204584</td>\n",
       "      <td>3.166049</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoded_feature_0  encoded_feature_1  encoded_feature_2  encoded_feature_3  \\\n",
       "0          -0.168524          -0.057372           0.102818          -0.243955   \n",
       "1          -0.162565          -0.060451           0.094373          -0.243832   \n",
       "2          -0.164049          -0.259337          -0.201851          -0.278407   \n",
       "3          -0.271798          -0.055786          -0.239978          -0.229345   \n",
       "4          -0.269069          -0.106385          -0.235731          -0.240414   \n",
       "\n",
       "   encoded_feature_4  encoded_feature_5  encoded_feature_6  encoded_feature_7  \\\n",
       "0          -0.202454          -0.104967           0.321823          -0.222371   \n",
       "1          -0.207173          -0.107619           0.317791          -0.222770   \n",
       "2          -0.252687          -0.257245           0.225601          -0.249530   \n",
       "3          -0.060237          -0.220229           0.733118          -0.208833   \n",
       "4          -0.079836          -0.237433           0.665825          -0.209488   \n",
       "\n",
       "   encoded_feature_8  encoded_feature_9  ...  encoded_feature_11  \\\n",
       "0          -0.262240          -0.180430  ...           -0.258119   \n",
       "1          -0.263774          -0.184074  ...           -0.257707   \n",
       "2          -0.273658          -0.244420  ...           -0.042617   \n",
       "3          -0.147414          -0.217443  ...           -0.012005   \n",
       "4          -0.180263          -0.203104  ...           -0.017777   \n",
       "\n",
       "   encoded_feature_12  encoded_feature_13  encoded_feature_14  \\\n",
       "0           -0.242541           -0.157287           -0.145760   \n",
       "1           -0.245912           -0.156141           -0.148324   \n",
       "2           -0.223356           -0.231683           -0.271294   \n",
       "3           -0.107234           -0.278464           -0.162567   \n",
       "4           -0.128438           -0.277465           -0.186881   \n",
       "\n",
       "   encoded_feature_15  responder_6    weight  symbol_id  date_id  time_id  \n",
       "0            0.005600     0.496563  3.324375          0     1000        0  \n",
       "1           -0.013658     0.529877  4.711303          1     1000        0  \n",
       "2            0.407031     0.746983  3.028847          2     1000        0  \n",
       "3           -0.258254     0.941218  2.099438          3     1000        0  \n",
       "4           -0.277370     0.204584  3.166049          4     1000        0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trick of boosting LB score, data leakage on the validation set\n",
    "# train = pd.concat([train, valid]).reset_index(drop=True)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2.3 Use KNN imputation (yes, KNN can be used to impute missing values!)\n",
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# imputer = KNNImputer(n_neighbors=5)\n",
    "# X_train = imputer.fit_transform(train[CONFIG.feature_cols])\n",
    "# X_valid = imputer.transform(valid[CONFIG.feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train[ CONFIG.feature_cols ]\n",
    "# X_train = X_train.ffill().fillna(0)\n",
    "# y_train = train[ CONFIG.target_col ]\n",
    "# w_train = train[\"weight\"]\n",
    "\n",
    "# X_valid = valid[ CONFIG.feature_cols ]\n",
    "# X_valid = X_valid.ffill().fillna(0)\n",
    "# y_valid = valid[ CONFIG.target_col ]\n",
    "# w_valid = valid[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[ CONFIG.encoded_cols ]\n",
    "y_train = train[ CONFIG.target_col ]\n",
    "w_train = train[\"weight\"]\n",
    "\n",
    "X_valid = valid[ CONFIG.encoded_cols ]\n",
    "y_valid = valid[ CONFIG.target_col ]\n",
    "w_valid = valid[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymbolKNNRegressor:\n",
    "    def __init__(self, n_neighbors=5, window_dates=50):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.window_dates = window_dates\n",
    "        self.symbol_models = {}  # Dictionary to store KNN models for each symbol\n",
    "        \n",
    "    def fit(self, X, y, symbol_ids, date_ids):\n",
    "        # Get unique symbols\n",
    "        unique_symbols = np.unique(symbol_ids)\n",
    "        \n",
    "        # For each symbol, create and fit a KNN model\n",
    "        for symbol in tqdm(unique_symbols, desc=\"Fitting models for symbols\"):\n",
    "            # Get data for this symbol\n",
    "            symbol_mask = symbol_ids == symbol\n",
    "            X_symbol = X[symbol_mask]\n",
    "            y_symbol = y[symbol_mask]\n",
    "            dates_symbol = date_ids[symbol_mask]\n",
    "            \n",
    "            # Get the most recent dates for this symbol\n",
    "            recent_dates = sorted(set(dates_symbol))[-self.window_dates:]\n",
    "            recent_mask = np.isin(dates_symbol, recent_dates)\n",
    "            \n",
    "            # Filter data to recent dates\n",
    "            X_recent = X_symbol[recent_mask]\n",
    "            y_recent = y_symbol[recent_mask]\n",
    "            \n",
    "            # Only create model if we have enough data\n",
    "            if len(X_recent) > self.n_neighbors:\n",
    "                # Create and fit KNN model for this symbol\n",
    "                knn = KNeighborsRegressor(\n",
    "                    n_neighbors=min(self.n_neighbors, len(X_recent)),\n",
    "                    weights='distance',\n",
    "                    algorithm='ball_tree',\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                knn.fit(X_recent, y_recent)\n",
    "                self.symbol_models[symbol] = knn\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, symbol_ids):\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        # Group test data by symbol for batch processing\n",
    "        unique_symbols = np.unique(symbol_ids)\n",
    "        \n",
    "        for symbol in unique_symbols:\n",
    "            # Get mask for current symbol\n",
    "            symbol_mask = symbol_ids == symbol\n",
    "            \n",
    "            # If we have a model for this symbol\n",
    "            if symbol in self.symbol_models:\n",
    "                predictions[symbol_mask] = self.symbol_models[symbol].predict(X[symbol_mask])\n",
    "            # If symbol is not in training data, prediction remains 0\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# Modified parallel prediction function\n",
    "def predict_batch(model, X_batch, symbol_ids_batch):\n",
    "    return model.predict(X_batch, symbol_ids_batch)\n",
    "\n",
    "def parallel_predict(model, X, symbol_ids, batch_size=10000, n_workers=8):\n",
    "    n_samples = len(X)\n",
    "    predictions = np.zeros(n_samples)\n",
    "    \n",
    "    # Create batches\n",
    "    batches = [(model, X[i:i+batch_size], symbol_ids[i:i+batch_size]) \n",
    "               for i in range(0, n_samples, batch_size)]\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = []\n",
    "        for i, (model, batch, symbol_batch) in enumerate(batches):\n",
    "            future = executor.submit(predict_batch, model, batch, symbol_batch)\n",
    "            futures.append((i, future))\n",
    "        \n",
    "        # Collect results\n",
    "        for i, future in tqdm(futures, desc=\"Processing batches\"):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, n_samples)\n",
    "            predictions[start_idx:end_idx] = future.result()\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models for symbols: 100%|██████████| 39/39 [00:17<00:00,  2.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SymbolKNNRegressor at 0x7f3838c24940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage example:\n",
    "symbol_knn = SymbolKNNRegressor(n_neighbors=3, window_dates=20)\n",
    "symbol_knn.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    train[\"symbol_id\"],\n",
    "    train[\"date_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/jane_street/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "If you really know what your doing, you can silence this warning with the warning module\n",
      "or by setting POLARS_ALLOW_FORKING_THREAD=1.\n",
      "\n",
      "  self.pid = os.fork()\n",
      "Processing batches: 100%|██████████| 165/165 [01:44<00:00,  1.58it/s]/root/miniconda3/envs/jane_street/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "If you really know what your doing, you can silence this warning with the warning module\n",
      "or by setting POLARS_ALLOW_FORKING_THREAD=1.\n",
      "\n",
      "  self.pid = os.fork()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_valid = parallel_predict(\n",
    "    symbol_knn, \n",
    "    X_valid, \n",
    "    valid[\"symbol_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score: 0.185186169717505\n"
     ]
    }
   ],
   "source": [
    "# Calculate score\n",
    "valid_score = r2_score(y_valid, y_pred_valid, sample_weight=w_valid)\n",
    "print(f\"Validation Score: {valid_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"model\" : symbol_knn,\n",
    "    \"cv\" : valid_score\n",
    "}\n",
    "with open(\"knn_group.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(result, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RecentKNNRegressor:\n",
    "#     def __init__(self, n_neighbors=5, window_size=None):\n",
    "#         self.n_neighbors = n_neighbors\n",
    "#         self.window_size = window_size\n",
    "#         self.knn = KNeighborsRegressor(\n",
    "#             n_neighbors=n_neighbors,\n",
    "#             weights='distance',\n",
    "#             algorithm='ball_tree',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "#         # self.scaler = StandardScaler()\n",
    "        \n",
    "#     def fit(self, X, y, date_ids=None):\n",
    "#         # Filter recent data if window_size is specified\n",
    "#         if self.window_size and date_ids is not None:\n",
    "#             recent_dates = sorted(set(date_ids))[-self.window_size:]\n",
    "#             mask = np.isin(date_ids, recent_dates)\n",
    "#             X = X[mask]\n",
    "#             y = y[mask]\n",
    "        \n",
    "#         # # Scale features\n",
    "#         # X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "#         # Fit KNN with sample weights\n",
    "#         self.knn.fit(X, y)\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         # X_scaled = self.scaler.transform(X)\n",
    "#         return self.knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train single model with recent data and weights\n",
    "# recent_knn = RecentKNNRegressor(n_neighbors=5, window_size=200)\n",
    "# recent_knn.fit(\n",
    "#     X_train, \n",
    "#     y_train,\n",
    "#     date_ids=train[\"date_id\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_reg = KNeighborsRegressor(\n",
    "#     n_neighbors=5,\n",
    "#     weights='distance',\n",
    "#     algorithm='ball_tree',\n",
    "#     n_jobs=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_batch(model, X_batch):\n",
    "#     return model.predict(X_batch)\n",
    "\n",
    "# def parallel_predict(model, X, batch_size=10000, n_workers=8):\n",
    "#     n_samples = len(X)\n",
    "#     predictions = np.zeros(n_samples)\n",
    "    \n",
    "#     # Create batches\n",
    "#     batches = [(model, X[i:i+batch_size]) \n",
    "#                for i in range(0, n_samples, batch_size)]\n",
    "    \n",
    "#     with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "#         futures = []\n",
    "#         for i, (model, batch) in enumerate(batches):\n",
    "#             future = executor.submit(predict_batch, model, batch)\n",
    "#             futures.append((i, future))\n",
    "        \n",
    "#         # Collect results\n",
    "#         for i, future in tqdm(futures, desc=\"Processing batches\"):\n",
    "#             start_idx = i * batch_size\n",
    "#             end_idx = min((i + 1) * batch_size, n_samples)\n",
    "#             predictions[start_idx:end_idx] = future.result()\n",
    "    \n",
    "#     return predictions\n",
    "\n",
    "# # Usage\n",
    "# y_pred_valid = parallel_predict(recent_knn, X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_pred_valid = recent_knn.predict(X_valid)\n",
    "# valid_score = r2_score(y_valid, y_pred_valid, sample_weight=w_valid )\n",
    "# valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = {\n",
    "#     \"model\" : recent_knn,\n",
    "#     \"cv\" : valid_score\n",
    "# }\n",
    "# with open(\"knn_model.pkl\", \"wb\") as fp:\n",
    "#     pickle.dump(result, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jane_street",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
